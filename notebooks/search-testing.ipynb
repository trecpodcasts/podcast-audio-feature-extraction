{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "accepting-canvas",
   "metadata": {},
   "source": [
    "# Search Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dominant-wellington",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Want to be able to reload changed modules on the fly\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "characteristic-mistake",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 actual GPUs, 0 in use.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import Audio\n",
    "\n",
    "import src.search\n",
    "from src.data import load_metadata, find_paths\n",
    "\n",
    "import src.utils\n",
    "src.utils.gpu_setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vulnerable-evanescence",
   "metadata": {},
   "source": [
    "## Set up the searcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adjusted-telescope",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.1 s, sys: 760 ms, total: 9.86 s\n",
      "Wall time: 11.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Set up the searcher\n",
    "searcher = src.search.Searcher(\"../config.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capital-shareware",
   "metadata": {},
   "source": [
    "## Query: \"near death experiences\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "obvious-celtic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Elasticsearch query... returned 100 segments in 0.87 seconds\n",
      "Getting rerank scores for segments... returned 100 scores in 20.06 seconds\n",
      "Getting audio scores for 74 segments... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [17:31<00:00, 14.20s/it]\n",
      "/unix/cdtdisspotify/jtingey/podcast-dataset/src/search/features.py:46: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return (p/np.sum(p,axis=0)).T\n"
     ]
    }
   ],
   "source": [
    "query_title = \"near death experiences\"\n",
    "query_desc = \"I wonder if people have shared near-death experiences in podcast episodes.  I would like to find and listen to some stories.  I am not interested in the science of near-death experiences.\"\n",
    "search_df_0 = searcher.search(query_title, query_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "representative-official",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only 6 'entertaining' segments found, appending topical rank...\n"
     ]
    }
   ],
   "source": [
    "search_ids_0 = searcher.rerank(search_df_0)\n",
    "id_file = open(\"near-death-experiences-ids.json\", \"w\")\n",
    "json.dump(search_ids_0, id_file)\n",
    "id_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trained-coupon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First highest topical score\n",
    "print(search_ids_0[\"topical\"][0])\n",
    "waveform = searcher.get_segment_audio(search_ids_0[\"topical\"][0])\n",
    "Audio(waveform, rate=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removable-treasury",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First highest entertaining score\n",
    "print(search_ids_0[\"entertaining\"][0])\n",
    "waveform = searcher.get_segment_audio(search_ids_0[\"entertaining\"][2])\n",
    "Audio(waveform, rate=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quick-trout",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First highest subjective score\n",
    "print(search_ids_0[\"subjective\"][0])\n",
    "waveform = searcher.get_segment_audio(search_ids_0[\"subjective\"][0])\n",
    "Audio(waveform, rate=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subtle-invention",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First highest discussion score\n",
    "print(search_ids_0[\"discussion\"][0])\n",
    "waveform = searcher.get_segment_audio(search_ids_0[\"discussion\"][0])\n",
    "Audio(waveform, rate=44100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contemporary-fundamental",
   "metadata": {},
   "source": [
    "## Query: \"black lives matter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ancient-reach",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Elasticsearch query... returned 100 segments in 3.25 seconds\n",
      "Getting rerank scores for segments... returned 100 scores in 19.40 seconds\n",
      "Getting audio scores for 49 segments... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [09:11<00:00, 11.26s/it]\n",
      "/unix/cdtdisspotify/jtingey/podcast-dataset/src/search/features.py:46: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return (p/np.sum(p,axis=0)).T\n"
     ]
    }
   ],
   "source": [
    "query_title = \"black lives matter\"\n",
    "query_desc = \"What do people mean when they say “black lives matter”?  I am interested in personal reflections that give context to the phrase “black lives matter” and why it is important to individuals.  News stores about Black Lives Matter protests are relevant as well.\"\n",
    "search_df_1 = searcher.search(query_title, query_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "central-arthritis",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_ids_1 = searcher.rerank(search_df_1)\n",
    "id_file = open(\"black-lives-matter-ids.json\", \"w\")\n",
    "json.dump(search_ids_1, id_file)\n",
    "id_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "later-quilt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First highest topical score\n",
    "print(search_ids_1[\"topical\"][0])\n",
    "waveform = searcher.get_segment_audio(search_ids_1[\"topical\"][0])\n",
    "Audio(waveform, rate=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medical-orleans",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First highest entertaining score\n",
    "print(search_ids_1[\"entertaining\"][0])\n",
    "waveform = searcher.get_segment_audio(search_ids_1[\"entertaining\"][0])\n",
    "Audio(waveform, rate=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "settled-copper",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First highest subjective score\n",
    "print(search_ids_1[\"subjective\"][0])\n",
    "waveform = searcher.get_segment_audio(search_ids_1[\"subjective\"][0])\n",
    "Audio(waveform, rate=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extreme-entry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First highest discussion score\n",
    "print(search_ids_1[\"discussion\"][0])\n",
    "waveform = searcher.get_segment_audio(search_ids_1[\"discussion\"][0])\n",
    "Audio(waveform, rate=44100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elder-immune",
   "metadata": {},
   "source": [
    "## Query: \"workplace diversity\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "enabling-bride",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Elasticsearch query... returned 100 segments in 0.17 seconds\n",
      "Getting rerank scores for segments... returned 100 scores in 19.43 seconds\n",
      "Getting audio scores for 43 segments... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [05:42<00:00,  7.96s/it]\n"
     ]
    }
   ],
   "source": [
    "query_title = \"workplace diversity\"\n",
    "query_desc = \"What are things companies are doing and could do to promote diversity in the workplace?  Things like workplace programs, initiatives, education, and outreach are relevant.  Discussion about the outcomes of these efforts are relevant as well.\"\n",
    "search_df_2 = searcher.search(query_title, query_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "sought-professional",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only 1 'entertaining' segments found, appending topical rank...\n",
      "Only 0 'subjective' segments found, appending topical rank...\n"
     ]
    }
   ],
   "source": [
    "search_ids_2 = searcher.rerank(search_df_2)\n",
    "id_file = open(\"workplace-diversity-ids.json\", \"w\")\n",
    "json.dump(search_ids_2, id_file)\n",
    "id_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "further-plant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First highest topical score\n",
    "print(search_ids_2[\"topical\"][0])\n",
    "waveform = searcher.get_segment_audio(search_ids_2[\"topical\"][0])\n",
    "Audio(waveform, rate=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considered-trustee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First highest entertaining score\n",
    "print(search_ids_2[\"entertaining\"][0])\n",
    "waveform = searcher.get_segment_audio(search_ids_2[\"entertaining\"][0])\n",
    "Audio(waveform, rate=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proud-momentum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First highest subjective score\n",
    "print(search_ids_2[\"subjective\"][0])\n",
    "waveform = searcher.get_segment_audio(search_ids_2[\"subjective\"][0])\n",
    "Audio(waveform, rate=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "russian-advantage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First highest discussion score\n",
    "print(search_ids_2[\"discussion\"][0])\n",
    "waveform = searcher.get_segment_audio(search_ids_2[\"discussion\"][0])\n",
    "Audio(waveform, rate=44100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "described-symphony",
   "metadata": {},
   "source": [
    "## Query: \"halloween stories and chat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "specified-austria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Elasticsearch query... returned 100 segments in 0.47 seconds\n",
      "Getting rerank scores for segments... returned 100 scores in 19.79 seconds\n",
      "Getting audio scores for 44 segments... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [10:15<00:00, 13.99s/it]\n",
      "/unix/cdtdisspotify/jtingey/podcast-dataset/src/search/features.py:46: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return (p/np.sum(p,axis=0)).T\n"
     ]
    }
   ],
   "source": [
    "query_title = \"halloween stories and chat\"\n",
    "query_desc = \"I love Halloween and I want to hear stories and conversations about things people have done to celebrate it.  I am not looking for information about the history of Halloween or generalities about how it is celebrated, I want specific stories from individuals.\"\n",
    "search_df_3 = searcher.search(query_title, query_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "martial-oliver",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only 5 'subjective' segments found, appending topical rank...\n"
     ]
    }
   ],
   "source": [
    "search_ids_3 = searcher.rerank(search_df_3)\n",
    "id_file = open(\"halloween-stories-and-chat-ids.json\", \"w\")\n",
    "json.dump(search_ids_3, id_file)\n",
    "id_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "damaged-roulette",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First highest topical score\n",
    "print(search_ids_3[\"topical\"][0])\n",
    "waveform = searcher.get_segment_audio(search_ids_3[\"topical\"][0])\n",
    "Audio(waveform, rate=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "north-antenna",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First highest entertaining score\n",
    "print(search_ids_3[\"entertaining\"][2])\n",
    "waveform = searcher.get_segment_audio(search_ids_3[\"entertaining\"][2])\n",
    "Audio(waveform, rate=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powerful-mention",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First highest subjective score\n",
    "print(search_ids_3[\"subjective\"][0])\n",
    "waveform = searcher.get_segment_audio(search_ids_3[\"subjective\"][0])\n",
    "Audio(waveform, rate=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-brunswick",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First highest discussion score\n",
    "print(search_ids_3[\"discussion\"][0])\n",
    "waveform = searcher.get_segment_audio(search_ids_3[\"discussion\"][0])\n",
    "Audio(waveform, rate=44100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bridal-airline",
   "metadata": {},
   "source": [
    "## Generating random lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "composite-trading",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the id dicts...\n",
    "a_file = open(\"near-death-experiences-ids.json\", \"r\")\n",
    "search_ids_0 = a_file.read()\n",
    "search_ids_0 = json.loads(search_ids_0)\n",
    "a_file.close()\n",
    "\n",
    "a_file = open(\"black-lives-matter-ids.json\", \"r\")\n",
    "search_ids_1 = a_file.read()\n",
    "search_ids_1 = json.loads(search_ids_1)\n",
    "a_file.close()\n",
    "\n",
    "a_file = open(\"workplace-diversity-ids.json\", \"r\")\n",
    "search_ids_2 = a_file.read()\n",
    "search_ids_2 = json.loads(search_ids_2)\n",
    "a_file.close()\n",
    "\n",
    "a_file = open(\"halloween-stories-and-chat-ids.json\", \"r\")\n",
    "search_ids_3 = a_file.read()\n",
    "search_ids_3 = json.loads(search_ids_3)\n",
    "a_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "still-breach",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add different mood lists together for each\n",
    "search_ids_0_comb = sum(search_ids_0.values(), [])\n",
    "search_ids_1_comb = sum(search_ids_1.values(), [])\n",
    "search_ids_2_comb = sum(search_ids_2.values(), [])\n",
    "search_ids_3_comb = sum(search_ids_3.values(), [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "saving-boost",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find unique ids\n",
    "search_ids_0_set = set(search_ids_0_comb)\n",
    "search_ids_1_set = set(search_ids_1_comb)\n",
    "search_ids_2_set = set(search_ids_2_comb)\n",
    "search_ids_3_set = set(search_ids_3_comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "corporate-cornell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "27\n",
      "13\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "print(len(search_ids_0_set))\n",
    "print(len(search_ids_1_set))\n",
    "print(len(search_ids_2_set))\n",
    "print(len(search_ids_3_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "violent-landing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'3FpXzNnV6p1zGrKntTuBwJ_480', '3FpXzNnV6p1zGrKntTuBwJ_180', '081C1aKHqRm3TLE5HfNFnJ_2820', '3FpXzNnV6p1zGrKntTuBwJ_1920', '2OpWYbK7lrZqo1RIL7aZXN_840', '6ryjkPOTQSD894X8408Gua_780', '3FpXzNnV6p1zGrKntTuBwJ_240', '6ryjkPOTQSD894X8408Gua_840', '3FpXzNnV6p1zGrKntTuBwJ_60', '2OpWYbK7lrZqo1RIL7aZXN_1620', '2OpWYbK7lrZqo1RIL7aZXN_900', '2mAS7kzNeqWYbENsPYti0M_1080', '2OpWYbK7lrZqo1RIL7aZXN_1680', '2OpWYbK7lrZqo1RIL7aZXN_60', '5mDIjsJihGSHJSq5oyPgux_0', '3FpXzNnV6p1zGrKntTuBwJ_1500', '7F5kSbXhBx6LdhfJ09Fnsy_300', '1gncCb6vqP89WL8svVgGBq_240', '5sTWLPTj2kEVTD2Gs0hp16_2640', '5DXiyNJMCJu7ZJTvN6K4zG_60', '2OpWYbK7lrZqo1RIL7aZXN_120', '75a4qxnqCYVPPB00E7rvjh_2100', '3FpXzNnV6p1zGrKntTuBwJ_0'}\n",
      "{'2eKgAe2W243hPMJpYpD4Sm_3660', '3JoMKEfcvrKfBZ8grFwOgt_180', '1Mv8k3QtmXCbTBZgZatGTw_180', '6NuF9BV3moacBd7u6AxLU1_3240', '4q9AxryFxK0NYSTbnKemaj_2460', '2fmh46haAGGG37B625t4vC_360', '3amq9FA4tFZxXO4654OmFE_600', '0wC0hbvqCxAwa3nPz7HmSf_2460', '1oBaNfo2TZZCYg5T5Lk01J_1200', '7jYoZ6xFGTEmZUQFltBg8u_1560', '5gjTAHSeMkZRzysib5XFuO_120', '7jYoZ6xFGTEmZUQFltBg8u_1440', '2eKgAe2W243hPMJpYpD4Sm_3720', '3amq9FA4tFZxXO4654OmFE_540', '0fZcqNiCis6c5ANoFDf1pB_300', '6CeqiWI7ZjzFXu4lMW4vKT_1800', '6rfBpcYhpCiZjM5gnZOL6f_1500', '2PM604ntoDpe74Jz0hzzc8_1680', '6vIUubo98mGwtHGcQ7FRP7_3780', '4FcseUnGpiuYQQ8CbnM5hk_2460', '6rfBpcYhpCiZjM5gnZOL6f_1560', '4FcseUnGpiuYQQ8CbnM5hk_2580', '4FcseUnGpiuYQQ8CbnM5hk_2400', '1X0CcUT4UzARCBVZANDSnn_1320', '2j5HYek7T9qIQGsgZfWZIE_1800', '4q9AxryFxK0NYSTbnKemaj_2400', '1Mv8k3QtmXCbTBZgZatGTw_120'}\n",
      "{'4w55oA9LB4eIe28WdWUy3K_60', '5kqHH6GiXuBSdB68LyTb9I_420', '6n1sHefqhXOGarTcQ2of1Z_180', '4w55oA9LB4eIe28WdWUy3K_360', '3qZWbASPk6Dq6YL8RAeFT2_0', '3qZWbASPk6Dq6YL8RAeFT2_60', '5kqHH6GiXuBSdB68LyTb9I_360', '6aFmZyJNn4mXeIGXwSrt4S_1020', '4w55oA9LB4eIe28WdWUy3K_420', '5kqHH6GiXuBSdB68LyTb9I_0', '4w55oA9LB4eIe28WdWUy3K_0', '5kqHH6GiXuBSdB68LyTb9I_60', '6n1sHefqhXOGarTcQ2of1Z_60'}\n",
      "{'0SqfzfiO8czUOG3fFlATyZ_3180', '7BHfXLY5Y1YXkNuOi0DQ74_780', '0SqfzfiO8czUOG3fFlATyZ_120', '0wwVe8G2sbt5CzsXS3yRVE_240', '0SqfzfiO8czUOG3fFlATyZ_2880', '1A3ypPx5dT59ixGKxQ3OKy_780', '2WHNiBAsKOtn5bNFIpMpCf_180', '0f3m5hyx1Y8ddOYQ8rjuAn_120', '1A3ypPx5dT59ixGKxQ3OKy_720', '6xAz6huWoAGu7Udih5MvKe_2040', '3sl4Q09BsFQRsBJ4t6Slkb_2040', '2NOGkGhSHOSBtpZPYlGt9A_60', '0wwVe8G2sbt5CzsXS3yRVE_720', '67CJO3J6AkMXznUKiY6eW2_0', '1A3ypPx5dT59ixGKxQ3OKy_960', '5RbbOQXi45s47YiPRzlUQz_60', '1x83ZnT25YIVnAqclEcQ4o_420', '3worFGvYH2WsAiajpO0zg2_3360', '0SqfzfiO8czUOG3fFlATyZ_2280', '1GybaPM4vGSmjUX1yFaGSp_2460', '40jDIuUbqQnchlGx5SC5Wv_180', '6x3B9jUK518ZxVnBxGpPih_0'}\n"
     ]
    }
   ],
   "source": [
    "# Print for each\n",
    "print(search_ids_0_set)\n",
    "print(search_ids_1_set)\n",
    "print(search_ids_2_set)\n",
    "print(search_ids_3_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earned-muslim",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "changed-chassis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the id dicts...\n",
    "a_file = open(\"data/near-death-experiences-ids.json\", \"r\")\n",
    "nde_ids = a_file.read()\n",
    "nde_ids = json.loads(nde_ids)\n",
    "a_file.close()\n",
    "\n",
    "a_file = open(\"data/black-lives-matter-ids.json\", \"r\")\n",
    "blm_ids = a_file.read()\n",
    "blm_ids = json.loads(blm_ids)\n",
    "a_file.close()\n",
    "\n",
    "a_file = open(\"data/halloween-stories-and-chat-ids.json\", \"r\")\n",
    "hsac_ids = a_file.read()\n",
    "hsac_ids = json.loads(hsac_ids)\n",
    "a_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "central-given",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the evaluated segments\n",
    "nde_df = pd.read_csv('./data/nde.csv')  \n",
    "blm_df = pd.read_csv('./data/blm.csv')  \n",
    "hsac_df = pd.read_csv('./data/hsac.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "substantial-hamburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(baseline_segs, our_segs, true_segs):\n",
    "    base_correct = 0\n",
    "    for seg in baseline_segs:\n",
    "        if seg in true_segs:\n",
    "            base_correct += 1\n",
    "    our_correct = 0\n",
    "    for seg in our_segs:\n",
    "        if seg in true_segs:\n",
    "            our_correct += 1\n",
    "    \n",
    "    print(\"Num true: {}, Num baseline: {}, Num ours: {}\".format(len(true_segs), len(baseline_segs), len(our_segs)))\n",
    "    print(\"Baseline correct: {}, Ours correct: {}\".format(base_correct, our_correct))\n",
    "    print(\"Baseline frac: {}, Ours frac: {}\".format((base_correct/len(baseline_segs)),(our_correct/len(our_segs))))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "posted-publisher",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num true: 26, Num baseline: 30, Num ours: 26\n",
      "Baseline correct: 6, Ours correct: 20\n",
      "Baseline frac: 0.2, Ours frac: 0.7692307692307693\n",
      "\n"
     ]
    }
   ],
   "source": [
    "true_funny_segs = []\n",
    "for index, row in nde_df.iterrows():\n",
    "    if \"funny\" in row[\"entertaining\"]:\n",
    "        true_funny_segs.append(row[\"uri\"].strip(\"spotify:episode:\") + \"_\" + str(row[\"timestamp\"]))\n",
    "for index, row in blm_df.iterrows():\n",
    "    if \"funny\" in row[\"entertaining\"]:\n",
    "        true_funny_segs.append(row[\"uri\"].strip(\"spotify:episode:\") + \"_\" + str(row[\"timestamp\"]))\n",
    "for index, row in hsac_df.iterrows():\n",
    "    if \"funny\" in row[\"entertaining\"]:\n",
    "        true_funny_segs.append(row[\"uri\"].strip(\"spotify:episode:\") + \"_\" + str(row[\"timestamp\"]))\n",
    "        \n",
    "our_funny_segs = []\n",
    "our_funny_segs.extend(nde_ids[\"entertaining\"][:6])\n",
    "our_funny_segs.extend(blm_ids[\"entertaining\"][:])\n",
    "our_funny_segs.extend(hsac_ids[\"entertaining\"][:])\n",
    "\n",
    "base_funny_segs = []\n",
    "base_funny_segs.extend(nde_ids[\"topical\"][:])\n",
    "base_funny_segs.extend(blm_ids[\"topical\"][:])\n",
    "base_funny_segs.extend(hsac_ids[\"topical\"][:])\n",
    "\n",
    "evaluate(base_funny_segs, our_funny_segs, true_funny_segs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eastern-illness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num true: 41, Num baseline: 30, Num ours: 30\n",
      "Baseline correct: 7, Ours correct: 13\n",
      "Baseline frac: 0.23333333333333334, Ours frac: 0.43333333333333335\n",
      "\n"
     ]
    }
   ],
   "source": [
    "true_discussion_segs = []\n",
    "for index, row in nde_df.iterrows():\n",
    "    if \"conversation\" in row[\"discussion\"] or \"debate\" in row[\"discussion\"]:\n",
    "        true_discussion_segs.append(row[\"uri\"].strip(\"spotify:episode:\") + \"_\" + str(row[\"timestamp\"]))\n",
    "for index, row in blm_df.iterrows():\n",
    "    if \"conversation\" in row[\"discussion\"] or \"debate\" in row[\"discussion\"]:\n",
    "        true_discussion_segs.append(row[\"uri\"].strip(\"spotify:episode:\") + \"_\" + str(row[\"timestamp\"]))\n",
    "for index, row in hsac_df.iterrows():\n",
    "    if \"conversation\" in row[\"discussion\"] or \"debate\" in row[\"discussion\"]:\n",
    "        true_discussion_segs.append(row[\"uri\"].strip(\"spotify:episode:\") + \"_\" + str(row[\"timestamp\"]))\n",
    "        \n",
    "our_discussion_segs = []\n",
    "our_discussion_segs.extend(nde_ids[\"discussion\"][:])\n",
    "our_discussion_segs.extend(blm_ids[\"discussion\"][:])\n",
    "our_discussion_segs.extend(hsac_ids[\"discussion\"][:])\n",
    "\n",
    "base_discussion_segs = []\n",
    "base_discussion_segs.extend(nde_ids[\"topical\"][:])\n",
    "base_discussion_segs.extend(blm_ids[\"topical\"][:])\n",
    "base_discussion_segs.extend(hsac_ids[\"topical\"][:])\n",
    "\n",
    "evaluate(base_discussion_segs, our_discussion_segs, true_discussion_segs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "comparable-paris",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num true: 30, Num baseline: 30, Num ours: 25\n",
      "Baseline correct: 11, Ours correct: 11\n",
      "Baseline frac: 0.36666666666666664, Ours frac: 0.44\n"
     ]
    }
   ],
   "source": [
    "true_subjective_segs = []\n",
    "for index, row in nde_df.iterrows():\n",
    "    if \"Disapproval\" in row[\"subjective\"] or \"Approval\" in row[\"subjective\"]:\n",
    "        true_subjective_segs.append(row[\"uri\"].strip(\"spotify:episode:\") + \"_\" + str(row[\"timestamp\"]))\n",
    "for index, row in blm_df.iterrows():\n",
    "    if \"Disapproval\" in row[\"subjective\"] or \"Approval\" in row[\"subjective\"]:\n",
    "        true_subjective_segs.append(row[\"uri\"].strip(\"spotify:episode:\") + \"_\" + str(row[\"timestamp\"]))\n",
    "for index, row in hsac_df.iterrows():\n",
    "    if \"Disapproval\" in row[\"subjective\"] or \"Approval\" in row[\"subjective\"]:\n",
    "        true_subjective_segs.append(row[\"uri\"].strip(\"spotify:episode:\") + \"_\" + str(row[\"timestamp\"]))\n",
    "        \n",
    "our_subjective_segs = []\n",
    "our_subjective_segs.extend(nde_ids[\"subjective\"][:])\n",
    "our_subjective_segs.extend(blm_ids[\"subjective\"][:])\n",
    "our_subjective_segs.extend(hsac_ids[\"subjective\"][:5])\n",
    "\n",
    "base_subjective_segs = []\n",
    "base_subjective_segs.extend(nde_ids[\"topical\"][:])\n",
    "base_subjective_segs.extend(blm_ids[\"topical\"][:])\n",
    "base_subjective_segs.extend(hsac_ids[\"topical\"][:])\n",
    "\n",
    "evaluate(base_subjective_segs, our_subjective_segs, true_subjective_segs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "advanced-sleep",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num true: 8, Num baseline: 10, Num ours: 6\n",
      "Baseline correct: 0, Ours correct: 6\n",
      "Baseline frac: 0.0, Ours frac: 1.0\n"
     ]
    }
   ],
   "source": [
    "true_funny_segs = []\n",
    "for index, row in nde_df.iterrows():\n",
    "    if \"funny\" in row[\"entertaining\"]:\n",
    "        true_funny_segs.append(row[\"uri\"].strip(\"spotify:episode:\") + \"_\" + str(row[\"timestamp\"]))\n",
    "evaluate(nde_ids[\"topical\"][:], nde_ids[\"entertaining\"][:6], true_funny_segs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "coral-funeral",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num true: 9, Num baseline: 10, Num ours: 10\n",
      "Baseline correct: 3, Ours correct: 7\n",
      "Baseline frac: 0.3, Ours frac: 0.7\n"
     ]
    }
   ],
   "source": [
    "true_funny_segs = []\n",
    "for index, row in blm_df.iterrows():\n",
    "    if \"funny\" in row[\"entertaining\"]:\n",
    "        true_funny_segs.append(row[\"uri\"].strip(\"spotify:episode:\") + \"_\" + str(row[\"timestamp\"]))\n",
    "evaluate(blm_ids[\"topical\"][:], blm_ids[\"entertaining\"][:], true_funny_segs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "acknowledged-speed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num true: 9, Num baseline: 10, Num ours: 10\n",
      "Baseline correct: 3, Ours correct: 7\n",
      "Baseline frac: 0.3, Ours frac: 0.7\n"
     ]
    }
   ],
   "source": [
    "true_funny_segs = []\n",
    "for index, row in hsac_df.iterrows():\n",
    "    if \"funny\" in row[\"entertaining\"]:\n",
    "        true_funny_segs.append(row[\"uri\"].strip(\"spotify:episode:\") + \"_\" + str(row[\"timestamp\"]))\n",
    "evaluate(hsac_ids[\"topical\"][:], hsac_ids[\"entertaining\"][:], true_funny_segs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "compatible-supervision",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num true: 11, Num baseline: 10, Num ours: 10\n",
      "Baseline correct: 0, Ours correct: 4\n",
      "Baseline frac: 0.0, Ours frac: 0.4\n"
     ]
    }
   ],
   "source": [
    "true_discussion_segs = []\n",
    "for index, row in nde_df.iterrows():\n",
    "    if \"conversation\" in row[\"discussion\"] or \"debate\" in row[\"discussion\"]:\n",
    "        true_discussion_segs.append(row[\"uri\"].strip(\"spotify:episode:\") + \"_\" + str(row[\"timestamp\"]))\n",
    "evaluate(nde_ids[\"topical\"][:], nde_ids[\"discussion\"][:], true_discussion_segs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "rotary-auckland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num true: 18, Num baseline: 10, Num ours: 10\n",
      "Baseline correct: 5, Ours correct: 8\n",
      "Baseline frac: 0.5, Ours frac: 0.8\n"
     ]
    }
   ],
   "source": [
    "true_discussion_segs = []\n",
    "for index, row in blm_df.iterrows():\n",
    "    if \"conversation\" in row[\"discussion\"] or \"debate\" in row[\"discussion\"]:\n",
    "        true_discussion_segs.append(row[\"uri\"].strip(\"spotify:episode:\") + \"_\" + str(row[\"timestamp\"]))\n",
    "evaluate(blm_ids[\"topical\"][:], blm_ids[\"discussion\"][:], true_discussion_segs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "advisory-alexandria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num true: 12, Num baseline: 10, Num ours: 10\n",
      "Baseline correct: 2, Ours correct: 1\n",
      "Baseline frac: 0.2, Ours frac: 0.1\n"
     ]
    }
   ],
   "source": [
    "true_discussion_segs = []\n",
    "for index, row in hsac_df.iterrows():\n",
    "    if \"conversation\" in row[\"discussion\"] or \"debate\" in row[\"discussion\"]:\n",
    "        true_discussion_segs.append(row[\"uri\"].strip(\"spotify:episode:\") + \"_\" + str(row[\"timestamp\"]))\n",
    "evaluate(hsac_ids[\"topical\"][:], hsac_ids[\"discussion\"][:], true_discussion_segs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "individual-cabin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num true: 8, Num baseline: 10, Num ours: 10\n",
      "Baseline correct: 3, Ours correct: 4\n",
      "Baseline frac: 0.3, Ours frac: 0.4\n"
     ]
    }
   ],
   "source": [
    "true_subjective_segs = []\n",
    "for index, row in nde_df.iterrows():\n",
    "    if \"Disapproval\" in row[\"subjective\"] or \"Approval\" in row[\"subjective\"]:\n",
    "        true_subjective_segs.append(row[\"uri\"].strip(\"spotify:episode:\") + \"_\" + str(row[\"timestamp\"]))\n",
    "evaluate(nde_ids[\"topical\"][:], nde_ids[\"subjective\"][:], true_subjective_segs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "durable-center",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num true: 17, Num baseline: 10, Num ours: 10\n",
      "Baseline correct: 5, Ours correct: 5\n",
      "Baseline frac: 0.5, Ours frac: 0.5\n"
     ]
    }
   ],
   "source": [
    "true_subjective_segs = []\n",
    "for index, row in blm_df.iterrows():\n",
    "    if \"Disapproval\" in row[\"subjective\"] or \"Approval\" in row[\"subjective\"]:\n",
    "        true_subjective_segs.append(row[\"uri\"].strip(\"spotify:episode:\") + \"_\" + str(row[\"timestamp\"]))\n",
    "evaluate(blm_ids[\"topical\"][:], blm_ids[\"subjective\"][:], true_subjective_segs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "legislative-control",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num true: 5, Num baseline: 10, Num ours: 5\n",
      "Baseline correct: 3, Ours correct: 2\n",
      "Baseline frac: 0.3, Ours frac: 0.4\n"
     ]
    }
   ],
   "source": [
    "true_subjective_segs = []\n",
    "for index, row in hsac_df.iterrows():\n",
    "    if \"Disapproval\" in row[\"subjective\"] or \"Approval\" in row[\"subjective\"]:\n",
    "        true_subjective_segs.append(row[\"uri\"].strip(\"spotify:episode:\") + \"_\" + str(row[\"timestamp\"]))\n",
    "evaluate(hsac_ids[\"topical\"][:], hsac_ids[\"subjective\"][:5], true_subjective_segs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "social-scott",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
